{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "VimbBZOkr3ja",
        "outputId": "213389a5-ad9f-4ffa-f008-059afc214535"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Début du nettoyage...\n",
            "\n",
            "1. Chargement BLS...\n",
            "   → BLS 2024 chargé\n",
            "   → bls_clean.csv & bls_metro_agg.csv sauvegardés\n",
            "\n",
            "2. Chargement IRS...\n",
            "   → irs_clean.csv sauvegardé\n",
            "\n",
            "3. Chargement Zillow ZIP...\n",
            "   → housing_zip_clean.csv & zip_metro_mapping.csv sauvegardés\n",
            "\n",
            "4. Chargement Zillow Metro...\n",
            "   → metro_income_buy → Income_Needed_Buy\n",
            "   → metro_income_rent → Income_Needed_Rent\n",
            "   → metro_days → DAYS\n",
            "   → metro_for_sale → FOR\n",
            "   → metro_heat → HEAT\n",
            "   → metro_sales → SALES\n",
            "   → housing_metro_clean.csv sauvegardé avec succès !\n",
            "\n",
            "5. Calculs d'affordability...\n",
            "\n",
            "Nettoyage terminé ! Fichiers dans : /Users/berline/Documents/M2_Miashs/OpenData/USA_Real_Estate-Dashboard/data/data_cleaned\n",
            "Fichiers générés :\n",
            "  - affordability_metro.csv\n",
            "  - affordability_zip.csv\n",
            "  - bls_clean.csv\n",
            "  - bls_metro_agg.csv\n",
            "  - housing_metro_clean.csv\n",
            "  - housing_zip_clean.csv\n",
            "  - irs_clean.csv\n",
            "  - zip_metro_mapping.csv\n"
          ]
        }
      ],
      "source": [
        "# --- CONFIG ---\n",
        "base_dir = '../data/'\n",
        "cleaned_dir = '../data/data_cleaned/'\n",
        "os.makedirs(cleaned_dir, exist_ok=True)\n",
        "\n",
        "# Chemins\n",
        "bls_2023_path = os.path.join(base_dir, 'BLS/all_data_M_2023.xlsx')\n",
        "bls_2024_path = os.path.join(base_dir, 'BLS/all_data_M_2024.xlsx')\n",
        "irs_path = os.path.join(base_dir, 'IRS/22zpallagi.csv')\n",
        "\n",
        "zillow_paths = {\n",
        "    'metro_days': os.path.join(base_dir, 'Zillow_datasets/Metro_days_on_market_mean_doz_pending_uc_sfrcondo_sm_month.csv'),\n",
        "    'metro_for_sale': os.path.join(base_dir, 'Zillow_datasets/Metro_for_sale_listings_invt_fs_uc_sfrcondo_sm_month.csv'),\n",
        "    'metro_heat': os.path.join(base_dir, 'Zillow_datasets/Metro_market_heat_index_uc_sfrcondo_month.csv'),\n",
        "    'metro_income_buy': os.path.join(base_dir, 'Zillow_datasets/Metro_new_homeowner_income_needed_downpayment_0.20_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'metro_income_rent': os.path.join(base_dir, 'Zillow_datasets/Metro_new_renter_income_needed_uc_sfrcondomfr_sm_sa_month.csv'),\n",
        "    'metro_sales': os.path.join(base_dir, 'Zillow_datasets/Metro_sales_count_now_uc_sfrcondo_month.csv'),\n",
        "    'zip_forecast': os.path.join(base_dir, 'Zillow_datasets/Zip_home_values_forecasts_zhvf_growth_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'zip_zhvi': os.path.join(base_dir, 'Zillow_datasets/Zip_home_values_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'zip_zori': os.path.join(base_dir, 'Zillow_datasets/Zip_rentals_zori_uc_sfrcondomfr_sm_month.csv')\n",
        "}\n",
        "\n",
        "# --- Fonction melt ---\n",
        "def melt_zillow_df(df, value_name='Value'):\n",
        "    id_cols = [col for col in df.columns if not col.startswith(('19', '20'))]\n",
        "    df_melted = pd.melt(df, id_vars=id_cols, var_name='Date', value_name=value_name)\n",
        "    df_melted['Date'] = pd.to_datetime(df_melted['Date'], errors='coerce')\n",
        "    df_melted = df_melted.dropna(subset=['Date', value_name])\n",
        "    return df_melted\n",
        "\n",
        "print(\"Début du nettoyage...\\n\")\n",
        "\n",
        "# --- 1. BLS ---\n",
        "print(\"1. Chargement BLS...\")\n",
        "try:\n",
        "    bls_df = pd.read_excel(bls_2024_path)\n",
        "    print(\"   → BLS 2024 chargé\")\n",
        "except Exception as e:\n",
        "    print(f\"   → Erreur BLS 2024 : {e}, fallback sur 2023\")\n",
        "    bls_df = pd.read_excel(bls_2023_path)\n",
        "\n",
        "bls_cols = ['AREA_TITLE', 'OCC_TITLE', 'TOT_EMP', 'A_MEDIAN', 'A_PCT10', 'A_PCT25', 'A_PCT75', 'A_PCT90', 'LOC_QUOTIENT']\n",
        "bls_df = bls_df[bls_cols].dropna(subset=['A_MEDIAN'])\n",
        "bls_df['A_MEDIAN'] = pd.to_numeric(bls_df['A_MEDIAN'], errors='coerce')\n",
        "bls_df['Metro'] = bls_df['AREA_TITLE'].str.replace(' MSA', '', regex=False).str.strip()\n",
        "\n",
        "bls_metro_agg = bls_df.groupby('Metro')['A_MEDIAN'].median().reset_index().rename(columns={'A_MEDIAN': 'Median_Wage_Metro'})\n",
        "\n",
        "bls_df.to_csv(os.path.join(cleaned_dir, 'bls_clean.csv'), index=False)\n",
        "bls_metro_agg.to_csv(os.path.join(cleaned_dir, 'bls_metro_agg.csv'), index=False)\n",
        "print(\"   → bls_clean.csv & bls_metro_agg.csv sauvegardés\\n\")\n",
        "\n",
        "# --- 2. IRS ---\n",
        "print(\"2. Chargement IRS...\")\n",
        "irs_df = pd.read_csv(irs_path)\n",
        "irs_df = irs_df[irs_df['zipcode'] != 0]\n",
        "irs_agg = irs_df.groupby('zipcode').agg(\n",
        "    Total_Returns=('N1', 'sum'),\n",
        "    Total_AGI=('A00100', 'sum')\n",
        ").reset_index()\n",
        "irs_agg['Avg_AGI'] = irs_agg['Total_AGI'] / irs_agg['Total_Returns']\n",
        "irs_agg['ZIP'] = irs_agg['zipcode'].astype(str).str.zfill(5)\n",
        "irs_agg = irs_agg[['ZIP', 'Avg_AGI', 'Total_Returns']]\n",
        "irs_agg.to_csv(os.path.join(cleaned_dir, 'irs_clean.csv'), index=False)\n",
        "print(\"   → irs_clean.csv sauvegardé\\n\")\n",
        "\n",
        "# --- 3. Zillow ZIP ---\n",
        "print(\"3. Chargement Zillow ZIP...\")\n",
        "zip_zhvi = melt_zillow_df(pd.read_csv(zillow_paths['zip_zhvi']), 'ZHVI')\n",
        "zip_zori = melt_zillow_df(pd.read_csv(zillow_paths['zip_zori']), 'ZORI')\n",
        "zip_forecast = melt_zillow_df(pd.read_csv(zillow_paths['zip_forecast']), 'ZHVF_Growth')\n",
        "\n",
        "mapping_df = pd.read_csv(zillow_paths['zip_zhvi'])[['RegionName', 'Metro', 'StateName']].drop_duplicates()\n",
        "mapping_df['ZIP'] = mapping_df['RegionName'].astype(str).str.zfill(5)\n",
        "mapping_df = mapping_df[['ZIP', 'Metro', 'StateName']]\n",
        "mapping_df.to_csv(os.path.join(cleaned_dir, 'zip_metro_mapping.csv'), index=False)\n",
        "\n",
        "housing_zip = zip_zhvi.merge(zip_zori, on=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName', 'Metro', 'Date'], how='outer')\n",
        "housing_zip = housing_zip.merge(zip_forecast, on=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName', 'Metro', 'Date'], how='outer')\n",
        "housing_zip['ZIP'] = housing_zip['RegionName'].astype(str).str.zfill(5)\n",
        "housing_zip.to_csv(os.path.join(cleaned_dir, 'housing_zip_clean.csv'), index=False)\n",
        "print(\"   → housing_zip_clean.csv & zip_metro_mapping.csv sauvegardés\\n\")\n",
        "\n",
        "# --- 4. Zillow Metro ---\n",
        "print(\"4. Chargement Zillow Metro...\")\n",
        "metro_dfs = {}\n",
        "metro_keys = {k: v for k, v in zillow_paths.items() if 'metro' in k.lower()}\n",
        "\n",
        "# Ordre garanti : income_buy en premier pour garantir la colonne Income_Needed_Buy\n",
        "ordered_keys = [\n",
        "    'metro_income_buy',   # → Income_Needed_Buy\n",
        "    'metro_income_rent',  # → Income_Needed_Rent\n",
        "    'metro_days',         # → DAYS\n",
        "    'metro_for_sale',     # → FOR_SALE\n",
        "    'metro_heat',         # → HEAT\n",
        "    'metro_sales'         # → SALES\n",
        "]\n",
        "ordered_keys = [k for k in ordered_keys if k in metro_keys]  # Garde seulement les existants\n",
        "\n",
        "for key in ordered_keys:\n",
        "    path = metro_keys[key]\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    # --- DÉTECTION PRÉCISE DU TYPE DE FICHIER ---\n",
        "    filename = os.path.basename(path).lower()\n",
        "    \n",
        "    if 'homeowner_income_needed' in filename:\n",
        "        value_name = 'Income_Needed_Buy'\n",
        "    elif 'renter_income_needed' in filename:\n",
        "        value_name = 'Income_Needed_Rent'\n",
        "    else:\n",
        "        # Pour les autres : days, for_sale, heat, sales\n",
        "        part = key.split('_')[1]  # \"days\", \"for_sale\", etc.\n",
        "        value_name = part.upper().replace('_', '')  # DAYS, FORSALE, HEAT, SALES\n",
        "    \n",
        "    # --- Melt + Nettoyage ---\n",
        "    df_melted = melt_zillow_df(df, value_name)\n",
        "    df_clean = df_melted[['RegionName', 'Date', value_name]].copy()\n",
        "    \n",
        "    # Stocker\n",
        "    metro_dfs[key] = df_clean\n",
        "    print(f\"   → {key} → {value_name}\")\n",
        "\n",
        "# --- Merge progressif (sans duplication de colonnes) ---\n",
        "base_key = ordered_keys[0]\n",
        "housing_metro = metro_dfs[base_key].copy()\n",
        "\n",
        "for key in ordered_keys[1:]:\n",
        "    df = metro_dfs[key]\n",
        "    value_col = df.columns[-1]  # ex: 'Income_Needed_Rent', 'DAYS', etc.\n",
        "    housing_metro = housing_metro.merge(\n",
        "        df[['RegionName', 'Date', value_col]],\n",
        "        on=['RegionName', 'Date'],\n",
        "        how='outer'\n",
        "    )\n",
        "\n",
        "# --- Ajouter la colonne Metro (une seule fois, à la fin) ---\n",
        "metro_name_df = pd.read_csv(zillow_paths[base_key])[['RegionName']].drop_duplicates()\n",
        "metro_name_df['Metro'] = metro_name_df['RegionName'].str.strip()\n",
        "housing_metro = housing_metro.merge(metro_name_df, on='RegionName', how='left')\n",
        "\n",
        "# --- Sauvegarde ---\n",
        "housing_metro.to_csv(os.path.join(cleaned_dir, 'housing_metro_clean.csv'), index=False)\n",
        "print(\"   → housing_metro_clean.csv sauvegardé avec succès !\\n\")\n",
        "\n",
        "\n",
        "# --- 5. Affordability ---\n",
        "print(\"5. Calculs d'affordability...\")\n",
        "\n",
        "# ZIP\n",
        "afford_zip = housing_zip.merge(mapping_df, on='ZIP', how='left').merge(irs_agg, on='ZIP', how='left')\n",
        "afford_zip['Monthly_Payment_Buy'] = (afford_zip['ZHVI'] * 0.8 * 0.07 / 12) + (afford_zip['ZHVI'] * 0.01 / 12)\n",
        "afford_zip['Income_Needed_Buy'] = afford_zip['Monthly_Payment_Buy'] * 12 / 0.3\n",
        "afford_zip['Income_Needed_Rent'] = (afford_zip['ZORI'] * 12) / 0.3\n",
        "afford_zip['Affordability_Ratio'] = (afford_zip['Monthly_Payment_Buy'] / (afford_zip['Avg_AGI'] / 12)).replace([np.inf, -np.inf], np.nan) * 100\n",
        "afford_zip['Years_To_Save_Downpayment'] = (afford_zip['ZHVI'] * 0.2) / (afford_zip['Avg_AGI'] * 0.1).replace([np.inf, -np.inf], np.nan)\n",
        "afford_zip.to_csv(os.path.join(cleaned_dir, 'affordability_zip.csv'), index=False)\n",
        "\n",
        "# Metro\n",
        "afford_metro = housing_metro.merge(bls_metro_agg, on='Metro', how='left')\n",
        "\n",
        "# Vérifier si Income_Needed_Buy existe\n",
        "if 'Income_Needed_Buy' in afford_metro.columns:\n",
        "    afford_metro['Afford_Ratio_vs_Wage'] = afford_metro['Income_Needed_Buy'] / afford_metro['Median_Wage_Metro']\n",
        "else:\n",
        "    print(\"   → 'Income_Needed_Buy' manquant dans housing_metro. Ratio non calculé.\")\n",
        "    afford_metro['Afford_Ratio_vs_Wage'] = np.nan\n",
        "\n",
        "afford_metro.to_csv(os.path.join(cleaned_dir, 'affordability_metro.csv'), index=False)\n",
        "\n",
        "print(f\"\\nNettoyage terminé ! Fichiers dans : {os.path.abspath(cleaned_dir)}\")\n",
        "print(\"Fichiers générés :\")\n",
        "for f in sorted(os.listdir(cleaned_dir)):\n",
        "    print(f\"  - {f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
