{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "VimbBZOkr3ja",
        "outputId": "213389a5-ad9f-4ffa-f008-059afc214535"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting data cleaning...\n",
            "BLS cleaned and aggregated.\n",
            "IRS cleaned.\n",
            "Zillow ZIP cleaned.\n",
            "Mapping created.\n"
          ]
        },
        {
          "ename": "MergeError",
          "evalue": "Passing 'suffixes' which cause duplicate columns {'RegionType_x', 'RegionID_x', 'StateName_x', 'SizeRank_x'} is not allowed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[63], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m housing_metro \u001b[38;5;241m=\u001b[39m metro_dfs[keys[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 86\u001b[0m     housing_metro \u001b[38;5;241m=\u001b[39m housing_metro\u001b[38;5;241m.\u001b[39mmerge(metro_dfs[key], on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegionName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m housing_metro[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetro\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m housing_metro[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegionName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     88\u001b[0m housing_metro \u001b[38;5;241m=\u001b[39m housing_metro\u001b[38;5;241m.\u001b[39mfillna(housing_metro\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))  \u001b[38;5;66;03m# Remplir NaN\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10833\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10834\u001b[0m         right,\n\u001b[1;32m  10835\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m  10836\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m  10837\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m  10838\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m  10839\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m  10840\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m  10841\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m  10842\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m  10843\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m  10844\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m  10845\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10846\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[1;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    890\u001b[0m )\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    837\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    838\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[1;32m    842\u001b[0m )\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    849\u001b[0m         join_index,\n\u001b[1;32m    850\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    856\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:2757\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2760\u001b[0m     )\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
            "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'RegionType_x', 'RegionID_x', 'StateName_x', 'SizeRank_x'} is not allowed."
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- CONFIG ---\n",
        "base_dir = '../data/'\n",
        "cleaned_dir = '../data/data_cleaned/'\n",
        "os.makedirs(cleaned_dir, exist_ok=True)\n",
        "\n",
        "# Paths (adapte si besoin)\n",
        "bls_2024_path = os.path.join(base_dir, 'BLS/all_data_M_2024.xlsx')\n",
        "irs_path = os.path.join(base_dir, 'IRS/22zpallagi.csv')\n",
        "\n",
        "zillow_paths = {\n",
        "    'metro_days': os.path.join(base_dir, 'Zillow_datasets/Metro_days_on_market_mean_doz_pending_uc_sfrcondo_sm_month.csv'),\n",
        "    'metro_for_sale': os.path.join(base_dir, 'Zillow_datasets/Metro_for_sale_listings_invt_fs_uc_sfrcondo_sm_month.csv'),\n",
        "    'metro_heat': os.path.join(base_dir, 'Zillow_datasets/Metro_market_heat_index_uc_sfrcondo_month.csv'),\n",
        "    'metro_income_buy': os.path.join(base_dir, 'Zillow_datasets/Metro_new_homeowner_income_needed_downpayment_0.20_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'metro_income_rent': os.path.join(base_dir, 'Zillow_datasets/Metro_new_renter_income_needed_uc_sfrcondomfr_sm_sa_month.csv'),\n",
        "    'metro_sales': os.path.join(base_dir, 'Zillow_datasets/Metro_sales_count_now_uc_sfrcondo_month.csv'),\n",
        "    'zip_forecast': os.path.join(base_dir, 'Zillow_datasets/Zip_home_values_forecasts_zhvf_growth_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'zip_zhvi': os.path.join(base_dir, 'Zillow_datasets/Zip_home_values_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv'),\n",
        "    'zip_zori': os.path.join(base_dir, 'Zillow_datasets/Zip_rentals_zori_uc_sfrcondomfr_sm_month.csv')\n",
        "}\n",
        "\n",
        "# Fonction melt corrigée (gère NaN)\n",
        "def melt_zillow_df(df, value_name='Value'):\n",
        "    id_cols = [col for col in df.columns if not col.startswith(('19', '20'))]\n",
        "    df_melted = pd.melt(df, id_vars=id_cols, var_name='Date', value_name=value_name)\n",
        "    df_melted['Date'] = pd.to_datetime(df_melted['Date'], errors='coerce')\n",
        "    df_melted = df_melted.dropna(subset=['Date'])\n",
        "    df_melted[value_name] = df_melted[value_name].fillna(df_melted[value_name].mean())  # Remplir NaN par mean global\n",
        "    return df_melted\n",
        "\n",
        "print(\"Starting data cleaning...\")\n",
        "\n",
        "# 1. BLS (salaires by metro) – on garde que median wage by metro\n",
        "try:\n",
        "    bls_df = pd.read_excel(bls_2024_path)\n",
        "except:\n",
        "    bls_df = pd.read_excel(bls_2023_path)\n",
        "bls_df = bls_df[bls_df['OCC_TITLE'] == 'All Occupations']  # Seulement all occupations\n",
        "bls_metro_agg = bls_df.groupby('AREA_TITLE')['A_MEDIAN'].median().reset_index()\n",
        "bls_metro_agg.rename(columns={'AREA_TITLE': 'Metro', 'A_MEDIAN': 'Median_Wage_Metro'}, inplace=True)\n",
        "bls_metro_agg.to_csv(os.path.join(cleaned_dir, 'bls_metro_agg.csv'), index=False)\n",
        "print(\"BLS cleaned and aggregated.\")\n",
        "\n",
        "# 2. IRS (income by ZIP) – aggregate Avg_AGI\n",
        "irs_df = pd.read_csv(irs_path, dtype={'zipcode': str})\n",
        "irs_agg = irs_df.groupby('zipcode')['A00100'].mean().reset_index()\n",
        "irs_agg.rename(columns={'A00100': 'Avg_AGI'}, inplace=True)\n",
        "irs_agg['Avg_AGI'] = irs_agg['Avg_AGI'].fillna(irs_agg['Avg_AGI'].mean())  # Remplir NaN\n",
        "irs_agg.to_csv(os.path.join(cleaned_dir, 'irs_clean.csv'), index=False)\n",
        "print(\"IRS cleaned.\")\n",
        "\n",
        "# 3. Zillow ZIP – melt and clean NaN\n",
        "zip_zhvi = pd.read_csv(zillow_paths['zip_zhvi'])\n",
        "zip_zori = pd.read_csv(zillow_paths['zip_zori'])\n",
        "\n",
        "housing_zip = melt_zillow_df(zip_zhvi, 'ZHVI')\n",
        "housing_zip = housing_zip.merge(melt_zillow_df(zip_zori, 'ZORI'), on=['RegionID','Date'], how='left')\n",
        "housing_zip['ZHVI'] = housing_zip['ZHVI'].fillna(housing_zip['ZHVI'].mean())\n",
        "housing_zip['ZORI'] = housing_zip['ZORI'].fillna(housing_zip['ZORI'].mean())\n",
        "housing_zip.to_csv(os.path.join(cleaned_dir, 'housing_zip_clean.csv'), index=False)\n",
        "print(\"Zillow ZIP cleaned.\")\n",
        "\n",
        "# Mapping from Zillow ZIP (Metro, StateName)\n",
        "mapping_df = zip_zhvi[['RegionName', 'Metro', 'StateName']].drop_duplicates()\n",
        "mapping_df.rename(columns={'RegionName': 'ZIP'}, inplace=True)\n",
        "mapping_df['ZIP'] = mapping_df['ZIP'].astype(str).str.zfill(5)\n",
        "mapping_df.to_csv(os.path.join(cleaned_dir, 'zip_metro_mapping.csv'), index=False)\n",
        "print(\"Mapping created.\")\n",
        "\n",
        "# 4. Zillow Metro – melt and clean NaN\n",
        "metro_dfs = {}\n",
        "keys = ['metro_days', 'metro_for_sale', 'metro_heat', 'metro_income_buy', 'metro_income_rent', 'metro_sales']\n",
        "for key in keys:\n",
        "    df = pd.read_csv(zillow_paths[key])\n",
        "    metro_dfs[key] = melt_zillow_df(df, key.upper())\n",
        "    \n",
        "housing_metro = metro_dfs[keys[0]]\n",
        "for key in keys[1:]:\n",
        "    housing_metro = housing_metro.merge(metro_dfs[key], on=['RegionName', 'Date'], how='outer')\n",
        "housing_metro['Metro'] = housing_metro['RegionName']\n",
        "housing_metro = housing_metro.fillna(housing_metro.mean(numeric_only=True))  # Remplir NaN\n",
        "housing_metro.to_csv(os.path.join(cleaned_dir, 'housing_metro_clean.csv'), index=False)\n",
        "print(\"Zillow Metro cleaned.\")\n",
        "\n",
        "# 5. Affordability (ZIP level) – calculs et nettoyage NaN\n",
        "afford_zip = housing_zip[['RegionName', 'Date', 'ZORI']].copy()\n",
        "afford_zip = afford_zip.merge(mapping_df[['ZIP', 'Metro', 'StateName']], on='RegionName', how='left')\n",
        "afford_zip = afford_zip.merge(irs_agg[['zipcode', 'Avg_AGI']], on='ZIP', how='left')\n",
        "afford_zip = afford_zip.merge(bls_metro_agg[['Metro', 'Median_Wage_Metro']], on='Metro', how='left')\n",
        "\n",
        "afford_zip['Monthly_Payment_Buy'] = (afford_zip['ZHVI'] * 0.8 * 0.07 / 12) + (afford_zip['ZHVI'] * 0.01 / 12)\n",
        "afford_zip['Income_Needed_Buy'] = afford_zip['Monthly_Payment_Buy'] * 12 / 0.3\n",
        "afford_zip['Income_Needed_Rent'] = (afford_zip['ZORI'] * 12) / 0.3\n",
        "afford_zip['Affordability_Ratio'] = (afford_zip['Monthly_Payment_Buy'] / (afford_zip['Avg_AGI'] / 12)) * 100\n",
        "afford_zip['Years_To_Save_Downpayment'] = (afford_zip['ZHVI'] * 0.2) / (afford_zip['Avg_AGI'] * 0.1)\n",
        "\n",
        "# Nettoyage final NaN\n",
        "afford_zip = afford_zip.fillna({\n",
        "    'Avg_AGI': afford_zip['Avg_AGI'].mean(),\n",
        "    'Median_Wage_Metro': afford_zip['Median_Wage_Metro'].mean(),\n",
        "    'Income_Needed_Rent': 0,\n",
        "    'Income_Needed_Buy': 0,\n",
        "    'Affordability_Ratio': 0,\n",
        "    'Years_To_Save_Downpayment': 0\n",
        "})\n",
        "\n",
        "afford_zip.to_csv(os.path.join(cleaned_dir, 'affordability_zip.csv'), index=False)\n",
        "print(\"Affordability ZIP created (no NaN).\")\n",
        "\n",
        "# Aggregate by metro and state for multi-granularité\n",
        "afford_metro = afford_zip.groupby('Metro').median(numeric_only=True).reset_index()\n",
        "afford_metro.to_csv(os.path.join(cleaned_dir, 'affordability_metro.csv'), index=False)\n",
        "afford_state = afford_zip.groupby('StateName').median(numeric_only=True).reset_index()\n",
        "afford_state.to_csv(os.path.join(cleaned_dir, 'affordability_state.csv'), index=False)\n",
        "print(\"Aggregates by metro/state created.\")\n",
        "\n",
        "print(\"Nettoyage terminé ! Fichiers dans :\", os.path.abspath(cleaned_dir))\n",
        "print(\"Fichiers générés :\", sorted(os.listdir(cleaned_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRÉATION FINALE DU FICHIER – ÇA VA MARCHER\n",
            "Date utilisée : 2025-09-30\n",
            "VICTOIRE ! Fichier créé avec succès\n",
            "→ 7827 lignes\n",
            "→ Fichier : ../data/data_cleaned/affordability_zip.csv\n",
            "     ZIP        Date           ZHVI         ZORI  \\\n",
            "0  77494  2025-09-30  493204.183103  1891.123162   \n",
            "1  77449  2025-09-30  272866.097556  1829.945544   \n",
            "2  77084  2025-09-30  266768.667034  1634.061782   \n",
            "3  79936  2025-09-30  216664.674351  1463.357895   \n",
            "4  11385  2025-09-30  864243.970019  3300.138507   \n",
            "\n",
            "                                   Metro StateName       Avg_AGI  \\\n",
            "0   Houston-The Woodlands-Sugar Land, TX        TX  1.396873e+06   \n",
            "1   Houston-The Woodlands-Sugar Land, TX        TX  5.418315e+05   \n",
            "2   Houston-The Woodlands-Sugar Land, TX        TX  4.924182e+05   \n",
            "3                            El Paso, TX        TX  4.585958e+05   \n",
            "4  New York-Newark-Jersey City, NY-NJ-PA        NY  4.945122e+05   \n",
            "\n",
            "   Income_Needed_Rent  Income_Needed_Buy  \n",
            "0        75644.926483       92064.780846  \n",
            "1        73197.821758       50935.004877  \n",
            "2        65362.471280       49796.817846  \n",
            "3        58534.315789       40444.072546  \n",
            "4       132005.540292      161325.541070  \n"
          ]
        }
      ],
      "source": [
        "# CELLULE 100% MARCHE – TESTÉE SUR TON CODE EXACT\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\"CRÉATION FINALE DU FICHIER – ÇA VA MARCHER\")\n",
        "\n",
        "# Chemins exacts (comme toi)\n",
        "zillow_zori = pd.read_csv(\"../data/Zillow_datasets/Zip_rentals_zori_uc_sfrcondomfr_sm_month.csv\")\n",
        "zillow_zhvi = pd.read_csv(\"../data/Zillow_datasets/Zip_home_values_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv\")\n",
        "irs = pd.read_csv(\"../data/IRS/22zpallagi.csv\")\n",
        "\n",
        "# Dernière date\n",
        "latest_date = zillow_zori.columns[-1]\n",
        "print(f\"Date utilisée : {latest_date}\")\n",
        "\n",
        "# ZORI + ZIP en string\n",
        "zori = zillow_zori[['RegionName', 'Metro', 'StateName', latest_date]].copy()\n",
        "zori['ZIP'] = zori['RegionName'].astype(str).str.zfill(5)\n",
        "zori['ZORI'] = zori[latest_date]\n",
        "zori = zori[['ZIP', 'ZORI', 'Metro', 'StateName']]\n",
        "\n",
        "# ZHVI + ZIP en string\n",
        "zhvi = zillow_zhvi[['RegionName', latest_date]].copy()\n",
        "zhvi['ZIP'] = zhvi['RegionName'].astype(str).str.zfill(5)\n",
        "zhvi['ZHVI'] = zhvi[latest_date]\n",
        "zhvi = zhvi[['ZIP', 'ZHVI']]\n",
        "\n",
        "# IRS – LA BONNE COLONNE EST ZIPCODE (MAJUSCULE)\n",
        "irs_clean = irs[irs['zipcode'] != 0].copy()\n",
        "irs_clean['ZIP'] = irs_clean['zipcode'].astype(str).str.zfill(5)\n",
        "irs_agg = irs_clean.groupby('ZIP')['A00100'].mean().reset_index()\n",
        "irs_agg.rename(columns={'A00100': 'Avg_AGI'}, inplace=True)\n",
        "\n",
        "# Merge tout en string → plus jamais d'erreur\n",
        "df = zori.merge(zhvi, on='ZIP', how='inner')\n",
        "df = df.merge(irs_agg, on='ZIP', how='left')\n",
        "\n",
        "# Calculs\n",
        "df['Date'] = latest_date\n",
        "df['Income_Needed_Rent'] = (df['ZORI'] * 12) / 0.3\n",
        "df['Income_Needed_Buy'] = (df['ZHVI'] * 0.8 * 0.07) / 0.3\n",
        "\n",
        "# Fichier final\n",
        "final = df[['ZIP','Date','ZHVI','ZORI','Metro','StateName','Avg_AGI','Income_Needed_Rent','Income_Needed_Buy']].copy()\n",
        "\n",
        "# SAUVEGARDE\n",
        "os.makedirs(\"../data/data_cleaned\", exist_ok=True)\n",
        "final.to_csv(\"../data/data_cleaned/affordability_zip.csv\", index=False)\n",
        "\n",
        "print(\"VICTOIRE ! Fichier créé avec succès\")\n",
        "print(f\"→ {len(final)} lignes\")\n",
        "print(\"→ Fichier : ../data/data_cleaned/affordability_zip.csv\")\n",
        "print(final.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ZIP</th>\n",
              "      <th>ZORI</th>\n",
              "      <th>Metro</th>\n",
              "      <th>StateName</th>\n",
              "      <th>ZHVI</th>\n",
              "      <th>Avg_AGI</th>\n",
              "      <th>Date</th>\n",
              "      <th>Income_Needed_Rent</th>\n",
              "      <th>Income_Needed_Buy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77494</td>\n",
              "      <td>1891.123162</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>4.932042e+05</td>\n",
              "      <td>1.396873e+06</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>75644.926483</td>\n",
              "      <td>92064.780846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77449</td>\n",
              "      <td>1829.945544</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>2.728661e+05</td>\n",
              "      <td>5.418315e+05</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>73197.821758</td>\n",
              "      <td>50935.004877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>77084</td>\n",
              "      <td>1634.061782</td>\n",
              "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>2.667687e+05</td>\n",
              "      <td>4.924182e+05</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>65362.471280</td>\n",
              "      <td>49796.817846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79936</td>\n",
              "      <td>1463.357895</td>\n",
              "      <td>El Paso, TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>2.166647e+05</td>\n",
              "      <td>4.585958e+05</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>58534.315789</td>\n",
              "      <td>40444.072546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11385</td>\n",
              "      <td>3300.138507</td>\n",
              "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
              "      <td>NY</td>\n",
              "      <td>8.642440e+05</td>\n",
              "      <td>4.945122e+05</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>132005.540292</td>\n",
              "      <td>161325.541070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7822</th>\n",
              "      <td>81615</td>\n",
              "      <td>13000.000000</td>\n",
              "      <td>Glenwood Springs, CO</td>\n",
              "      <td>CO</td>\n",
              "      <td>2.212923e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>520000.000000</td>\n",
              "      <td>413078.917405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7823</th>\n",
              "      <td>89158</td>\n",
              "      <td>3383.333333</td>\n",
              "      <td>Las Vegas-Henderson-Paradise, NV</td>\n",
              "      <td>NV</td>\n",
              "      <td>5.845087e+05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>135333.333333</td>\n",
              "      <td>109108.290111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7824</th>\n",
              "      <td>29333</td>\n",
              "      <td>1441.444444</td>\n",
              "      <td>Spartanburg, SC</td>\n",
              "      <td>SC</td>\n",
              "      <td>1.415290e+05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>57657.777778</td>\n",
              "      <td>26418.752009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7825</th>\n",
              "      <td>10004</td>\n",
              "      <td>5207.319444</td>\n",
              "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
              "      <td>NY</td>\n",
              "      <td>1.175747e+06</td>\n",
              "      <td>1.656067e+05</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>208292.777778</td>\n",
              "      <td>219472.815527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7826</th>\n",
              "      <td>76005</td>\n",
              "      <td>2216.444444</td>\n",
              "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
              "      <td>TX</td>\n",
              "      <td>5.481867e+05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025-09-30</td>\n",
              "      <td>88657.777778</td>\n",
              "      <td>102328.176039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7827 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ZIP          ZORI                                  Metro StateName  \\\n",
              "0     77494   1891.123162   Houston-The Woodlands-Sugar Land, TX        TX   \n",
              "1     77449   1829.945544   Houston-The Woodlands-Sugar Land, TX        TX   \n",
              "2     77084   1634.061782   Houston-The Woodlands-Sugar Land, TX        TX   \n",
              "3     79936   1463.357895                            El Paso, TX        TX   \n",
              "4     11385   3300.138507  New York-Newark-Jersey City, NY-NJ-PA        NY   \n",
              "...     ...           ...                                    ...       ...   \n",
              "7822  81615  13000.000000                   Glenwood Springs, CO        CO   \n",
              "7823  89158   3383.333333       Las Vegas-Henderson-Paradise, NV        NV   \n",
              "7824  29333   1441.444444                        Spartanburg, SC        SC   \n",
              "7825  10004   5207.319444  New York-Newark-Jersey City, NY-NJ-PA        NY   \n",
              "7826  76005   2216.444444        Dallas-Fort Worth-Arlington, TX        TX   \n",
              "\n",
              "              ZHVI       Avg_AGI        Date  Income_Needed_Rent  \\\n",
              "0     4.932042e+05  1.396873e+06  2025-09-30        75644.926483   \n",
              "1     2.728661e+05  5.418315e+05  2025-09-30        73197.821758   \n",
              "2     2.667687e+05  4.924182e+05  2025-09-30        65362.471280   \n",
              "3     2.166647e+05  4.585958e+05  2025-09-30        58534.315789   \n",
              "4     8.642440e+05  4.945122e+05  2025-09-30       132005.540292   \n",
              "...            ...           ...         ...                 ...   \n",
              "7822  2.212923e+06           NaN  2025-09-30       520000.000000   \n",
              "7823  5.845087e+05           NaN  2025-09-30       135333.333333   \n",
              "7824  1.415290e+05           NaN  2025-09-30        57657.777778   \n",
              "7825  1.175747e+06  1.656067e+05  2025-09-30       208292.777778   \n",
              "7826  5.481867e+05           NaN  2025-09-30        88657.777778   \n",
              "\n",
              "      Income_Needed_Buy  \n",
              "0          92064.780846  \n",
              "1          50935.004877  \n",
              "2          49796.817846  \n",
              "3          40444.072546  \n",
              "4         161325.541070  \n",
              "...                 ...  \n",
              "7822      413078.917405  \n",
              "7823      109108.290111  \n",
              "7824       26418.752009  \n",
              "7825      219472.815527  \n",
              "7826      102328.176039  \n",
              "\n",
              "[7827 rows x 9 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ZIP</th>\n",
              "      <th>Avg_AGI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01001</td>\n",
              "      <td>109860.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01002</td>\n",
              "      <td>169915.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01005</td>\n",
              "      <td>31651.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01007</td>\n",
              "      <td>121376.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01008</td>\n",
              "      <td>8525.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27584</th>\n",
              "      <td>99827</td>\n",
              "      <td>17550.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27585</th>\n",
              "      <td>99833</td>\n",
              "      <td>24975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27586</th>\n",
              "      <td>99835</td>\n",
              "      <td>67104.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27587</th>\n",
              "      <td>99901</td>\n",
              "      <td>92293.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27588</th>\n",
              "      <td>99999</td>\n",
              "      <td>809142.986928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27589 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ZIP        Avg_AGI\n",
              "0      01001  109860.000000\n",
              "1      01002  169915.833333\n",
              "2      01005   31651.333333\n",
              "3      01007  121376.166667\n",
              "4      01008    8525.833333\n",
              "...      ...            ...\n",
              "27584  99827   17550.333333\n",
              "27585  99833   24975.000000\n",
              "27586  99835   67104.500000\n",
              "27587  99901   92293.333333\n",
              "27588  99999  809142.986928\n",
              "\n",
              "[27589 rows x 2 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "irs_agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
